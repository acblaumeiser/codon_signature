{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML notes from fast.ai course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson source\n",
    "http://course18.fast.ai/ml.html\n",
    "\n",
    "Material source\n",
    "https://forums.fast.ai/t/fastai-v0-7-install-issues-thread/24652\n",
    "\n",
    "Data source\n",
    "https://www.kaggle.com/c/bluebook-for-bulldozers/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1\n",
    "### Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/bulldozers/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>!</code> is for execute in bash, <code>{}</code> is to take variables from python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step, **read the data with Pandas** (import always as pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(f'{PATH}Train.csv', low_memory=False, parse_dates=[\"saledate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>print (f'{PATH}Train.csv')</code> is a usefull strategy to concatenate strings with variables (also numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>parse_date=[\"column_name\"]</code> is to specify dates column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset is very big **do not use** <code>low_memory=FALSE</code> but create a dictionary containig the data type of each column and pass it to <code>read_csv</code> as <code>dtype=dict</code> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient way to save temporarily the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('tmp', exist_ok=True)\n",
    "df_raw.to_feather('tmp/bulldozers-raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And read it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_feather('tmp/bulldozers-raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the compuational time and the time used by each function, put the followings in front of the line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time or %prun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset is very large and you want to run RF many time is better to convert it in **np.array** before pass it to RF (RM does it automatically, but takes time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary analysis and general information about the table, <code>.T</code> is to get the trasnsposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.column_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use numpy (always import as np) to apply log to a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.SalePrice = np.log(df_raw.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>add_datepart</code> method extracts particular date fields from a complete datetime for the purpose of constructing categoricals. You should always consider this feature extraction step when working with date-time. Without expanding your date-time into these additional fields, you can't capture any trend/cyclical behavior as a function of time at any of these granularities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(df_raw, 'saledate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical variables are currently stored as strings, which is inefficient, and doesn't provide the numeric coding required for a random forest. Therefore we call <code>train_cats</code> to convert strings to pandas categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the order to use for categorical variables if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.UsageBand.cat.categories #return strings list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.UsageBand.cat.set_categories(['High', 'Medium', 'Low'], ordered=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the text categories with numbers, which will make this variable non-categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.UsageBand = df_raw.UsageBand.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get missing values proportion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(df_raw.isnull().sum().sort_index()/len(df_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With <code>proc_df</code> we can replace categories with their numeric codes, handle missing continuous values (replace with the median value, new bolean column to keep track), and split the dependent variable into a separate variables (in this case y becames **Sale Price** column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y, nas = proc_df(df_raw, 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RM model computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is possible to run RM, with **df** (df_raw without independent variable) and **y** as independent variable column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "m.fit(df, y)\n",
    "m.score(df,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>RandomForestRegresson</code> is used for continous values, while <code>RandomForestClassifier</code> is for categorical classification. <code>Fit</code> creates the model, and <code>score</code> return the r squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "m.fit(df, y)\n",
    "m.score(df,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>0.9825405552151154</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R squared very high could means **overfitting**, to check for it create a validation set\n",
    "\n",
    "\\\\( R^{2} \\\\) tells you how much your model is performing well respect to the naive model that always return the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to compute R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **total sum of squares** rappresent the proportion of the variance of the data, where \\\\( y_{i} \\\\) is the value and \\\\( \\bar{y} \\\\) is the mean of all values.\n",
    "\n",
    "\\\\[ SS_{tot}=\\sum (y_{i}-\\bar{y})^{2} \\\\]\n",
    "\n",
    "The **residual sum of square** reppresent the difference between the data \\\\( y_{i} \\\\) and the model result \\\\( f_{i} \\\\)\n",
    "\n",
    "\\\\[ SS_{res}=\\sum (y_{i}-f_{i})^{2} \\\\]\n",
    "\n",
    "The \\\\( R^{2} \\\\) is calculated as: \n",
    "\n",
    "\\\\[ R^{2} = 1 - \\frac{SS_{res}}{SS_{tot}} \\\\]\n",
    "\n",
    "The values are always lower than 1 and if \\\\( R^{2} \\\\) is lower than 0 means that the model is worst than predicting the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation set is a smaller than the training and do not contains trainig information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vals(a,n): return a[:n].copy(), a[n:].copy()\n",
    "\n",
    "n_valid = 12000  # same as Kaggle's test set size\n",
    "n_trn = len(df)-n_valid\n",
    "raw_train, raw_valid = split_vals(df_raw, n_trn)\n",
    "X_train, X_valid = split_vals(df, n_trn)\n",
    "y_train, y_valid = split_vals(y, n_trn)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then re-compute the model and verify for R2 and RMSE (Root Mean Squared Error, kaggle metric to evaluate the result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>CPU times: user 59.9 s, sys: 390 ms, total: 1min\n",
    "Wall time: 13.1 s\n",
    "[0.009070168709057988, 0.025989094636372057, 0.9824145830472109, 0.8775544278864014]</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset to speed up the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use <code>subset=</code> to porcess dataframe with <code>proc_df</code>. In order to do not change the validation set you can use <code>_</code> as variable name to do not consider it (python habit). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice', subset=30000)\n",
    "X_train, _ = split_vals(df_trn, 20000)\n",
    "y_train, _ = split_vals(y_trn, 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way the training process takes way less time but perform worst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a single tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>[17081.175032855852, 17724.36585854255, 0.43350834598758947, 0.46573300556577685]</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Where <code>n_estimators</code> is the number of tree and <code>max_depth</code> is the size of the tree, with <code>bootstrap=False</code> we do not randomise the data (**deterministic**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can draw a tree with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tree(m.estimators_[0], df_trn, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging\n",
    "Bagging is the strategy to put things togetherin order to sum up the prediction potential and minimalise the error of a single tree. \n",
    "In this context you can create a forest with many different tree that has to be as much different as possible at the cost to be little predictive by their own.\n",
    "\n",
    "\n",
    "The key is to find the ballance between poorly correlated trees done with many small diverse subset and trees higly correlated produced with more or less the same set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsampling strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we have 1M rows dataset and we decide to subsample to 20k, to do that use the command <code>set_rf_sample(20000)</code>. In this way we will have \\\\(\\log_2 20k \\\\) binary decison and 20k leaf nodes.\n",
    "Heavely subsampling give low overfitting and smaller trees (faster) but each single tree is less accurate.  \n",
    "The rule of the thumb is:\n",
    "- Each estimator (tree) has to be as much accurate as possible\n",
    "- The correlation between trees has to be as much lower as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code>RandomForestRegressor</code> parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>oob_score=True</code> (default is bootstrap) parameter to get a metric of the error using all the unused rows (kind of validation set) from the original dataset. It tells us if we are overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>min_sample_leaf=2</code> (default is 1) parameter to set the minimum number of element in the leaf node is 2, consequently we will have \\\\(\\log_2 20k-1 \\\\) binary decision and 10K leaf node.  \n",
    "Consequence are: \n",
    "- more stable average from each tree\n",
    "- less depth (decisions)\n",
    "- could avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>max_features=0.5</code> is set to use only half (randomly selected)of the columns at each decison. The reason is to increase **variety** of trees not using always the same features, in particular when few trees are produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>n_jobs=-1</code> is to use all cores available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is very common use logistic regression to quantify feautures imporatnce, in particular the regresson coefficent of each feature is the metric. This is not the best because the result is too dependent on previous assumption and could give missleading results (definitely based more on the strategy than on the data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to measure feature importance is to shuffle a column and compare the result. If the there are big changes means **high importance** if the result is the same the feature is not very relevant.  \n",
    "The code to get a table of it is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(m, df_trn)\n",
    "fi[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where <code>m</code> is the model and <code>df_trn</code> is the trainig set. The second line of code is used to print the 10 most important featires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have categorical columns like 'High', 'Low' and 'Medium' we can transform them into number 0, 1 and 2 with the function <code>train_cats</code>.  \n",
    "The other option is to use **one hot encoding** and create 3 new column with just 0/1 values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn2, y_trn, nas = proc_df(df_raw, 'SalePrice', max_n_cat=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where <code>max_n_cat=7</code> mean that every catecorical column is splitted in n different column qit 1/0 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a particular column in which we want to keep the code, just use <code>train_cats</code> anf then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.COLUMN_NAME = df.COLUMN_NAME.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove redundant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fist thing to do is to understand which are the column more similar to each other. Simple correlation between column could not work because it assume **linearity** that is not always present in our dataset.   \n",
    "The strategy is to use the **ranking correlation** such as **spearmanr** from scipy, but the values couple has to be monotnic (always going up or always down).  \n",
    "Then you can visualise it with a dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\n",
    "corr_condensed = hc.distance.squareform(1-corr)\n",
    "z = hc.linkage(corr_condensed, method='average')\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "dendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial dependence (what's going on on average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard way to observe dependance is to scatter plot two variables (dependent and one of the independent variable). Sometimes it happens that the points (or better the smoother) show strange behavior due to factor that we are not considering.  \n",
    "The **partial dependence plot** is a strategy that consists in trying a prediction using our model with the column of interest chagend to a constant, that has to be done for each value or category in order to get the plot (both single prediction and average) and try to interpret our data with less externalities.  \n",
    "The code to generate the plot is the following:\n",
    "(always subsample or it will take years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp\n",
    "from plotnine import *\n",
    "\n",
    "def plot_pdp(feat, clusters=None, feat_name=None):\n",
    "    feat_name = feat_name or feat\n",
    "    p = pdp.pdp_isolate(m, x, feat)\n",
    "    return pdp.pdp_plot(p, feat_name, plot_lines=True,\n",
    "                        cluster=clusters is not None,\n",
    "                        n_cluster_centers=clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdp('YearMade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or if we want to see cluster of lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdp('YearMade', clusters=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also very useful look at the PD of two independent variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['saleElapsed', 'YearMade']\n",
    "p = pdp.pdp_interact(m, x, feats)\n",
    "pdp.pdp_interact_plot(p, feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree interpreter for single observation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a look to a single observatio (row) we can use **tree interpreter** packadge.  \n",
    "We just have to extract the row from our dataset and pass it to <code>ti.predict</code> with the model and then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, bias, contributions = ti.predict(m, row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where <code>prediction</code> is the predicted value, <code>bias</code> is the average value of the dataset and <code>contribution</code> is a metrics about how much a feature is relevant in increasing or decreasing the prediction of the dependent variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The better way to visualise it is the **waterfall chart** where the first \"bar\" is the average value, the following \"bars\" are the negative or positive contribution of each feature and the last 2bar2 is the actual final prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the first step is to extract from the dataset random lines to create the validation and the test set. All the remaining rows is the **training** set. To be sure that the result is not working just for the training set, we use the **validation** set to compute the **validation score** and tune all the hyperparameter. Once the we are satisfied we can finally test the model with the **test** set.  \n",
    "If there is a time component, we can't use randomply picked rows but we have to use the latest data to generate the validation (more recent than training) and the test (more recent than validation) set.  \n",
    "In this way we are testing if **generalization**  is working in the time dimention, i.e. is our model able to predict the future using the past? \n",
    "To check everithing is working you can:\n",
    "- compute 5 or more model (different parameter or transformation)\n",
    "- get the validation score\n",
    "- retrain the model including the validation set\n",
    "- get the score with the test set\n",
    "- scatterplot of the resulting score (validation vs test for each model)\n",
    "- if the we get a linear relationship we are confident in merge validation and training\n",
    "- if not, rebuilt the models until the relationship is linear between test and validation  \n",
    "\n",
    "Once you are satisfied with the **validation** set, you can retrain the model **with exactly the same parameters** (here notebook are very helpful) but including also the validation set in the training. You have to be carefull to use the same parameter because at that point you will not be able anymore to \"validate\" but just use the **test** set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation score vs OOB score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two scores give a measure of the same thing but the OOB score is sligly less accurate because with the validation set we use the whole forest to make the prediction while the OOB score is the average of the subset of trees containing a given row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation is a strategy that consists in randomly shuffle, split the data in 5 chunks and the recursively use one of them as validation set and the remaining four as training set. Each of the five model give a result that can combine with the other one. The drawbacks are: \n",
    "- Not working with temporal data\n",
    "- Slow if big dataset\n",
    "- The validation set is random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extrapolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It happens that when you are predicting somthing in the future using data from the past the time component is too strong and and do not allows good prediction.  \n",
    "In order to quantify the time component importance the steps are:\n",
    "- create new column telling if the row is or not in the validation set. \n",
    "- built a model using the new column as dependent variable\n",
    "- check the \\\\( R^{2} \\\\), if is very high it means that the order (time scale) metter\n",
    "- check for the features importance and drop the more relevant \n",
    "- re-train the model and check again for feature importance, keep track of the more important\n",
    "- Finally train and score the origina dataset removing one of the **time relevant** column each at time\n",
    "- check if the score increase or not, if yes remove the column from the dataset because is too much time dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build your own tree from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide where to split a features in the decision tree we have to find the point in which the weighted average of the standard deviation of the two group is as low as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning is useful for model in which we want to explore somthing was not inside the training data, i.e. future time points, unconsidered situation...  \n",
    "\n",
    "A **neural network** is a linear layer folowed by an activation function, followed by a linear layer and so on.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differently from RM (care only about the order), we have to normalise the independent variable, because in DP the value matters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x.mean()\n",
    "std = x.std()\n",
    "\n",
    "x = (x-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way we get mean=0 and std=1, **the same mean and std has to be use with the validation set** (results is not perfectly 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = (x_valid-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a 2D tensor and we want to go back to 3d tesor (the immage) use <code>np.reshape></code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_imgs = np.reshape(x_valid, (-1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where -1, 28 and 28 mean, all the element (rows) have to be converted in a 3d tensor of 28x28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use a pretrained mode is mandfatory to use the same normalizzation coefficient used by the author of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with pythorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(28*28, 10),\n",
    "    nn.LogSoftmax()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each input is a vector of size `28*28` pixels and our output is of size `10` (since there are 10 digits: 0, 1, ..., 9). \n",
    "\n",
    "We use the output of the final layer to generate our predictions.  Often for classification problems (like MNIST digit classification), the final layer has the same number of outputs as there are classes.  In that case, this is 10: one for each digit from 0 to 9.  These can be converted to comparative probabilities.  For instance, it may be determined that a particular hand-written image is 80% likely to be a 4, 18% likely to be a 9, and 2% likely to be a 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have to create a model data `md` object that cointains all our set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ImageClassifierData.from_arrays('data/path', (x,y), (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.NLLLoss()\n",
    "metrics=[accuracy]\n",
    "# opt=optim.SGD(net.parameters(), 1e-1, momentum=0.9)\n",
    "opt=optim.SGD(net.parameters(), 1e-1, momentum=0.9, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(net, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_epochs=5` means go for every image five times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss functions and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning the **loss** function or cost function is representing the price paid for inaccuracy of predictions.\n",
    "\n",
    "The loss associated with one example in binary classification is given by:\n",
    "`-(y * log(p) + (1-y) * log (1-p))`\n",
    "where `y` is the true label of `x` and `p` is the probability predicted by our model that the label is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(y, p):\n",
    "    return np.mean(-(y * np.log(p) + (1-y)*np.log(1-p)))\n",
    "\n",
    "acts = np.array([1, 0, 0, 1])\n",
    "preds = np.array([0.9, 0.1, 0.2, 0.8])\n",
    "binary_loss(acts, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in our toy example above our accuracy is 100% and our loss is 0.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-class classification, we use negative log liklihood (also known as categorical cross entropy) which is exactly the same thing, but summed up over all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(net, md.val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a matrix with n rows as the number of element in the validation set and many columns as the `nn.Linear(28*28, `**10**`)` parameter asked for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to explore this matrix use `argmax` that return the index of the highest value of an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.argmax(axis=1)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return the top scoring value (looking at the row, axis=1) for the first 5 observation.  \n",
    "If we want to store just the best scoring value for each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then check how many observation has been properly predicted (**accuracy**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(preds == y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way we have just created **one layer neural net** that is a **logistic regression**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More layers.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(28*28, 100),\n",
    "    nn.ReLU()\n",
    "    nn.Linear(100, 10),\n",
    "    nn.LogSoftmax()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more layer is created adding <code>nn.Linear(100, 10)</code>, this will not change the result because they are just two linear layer (that is equal to one layer).  \n",
    "In order to make it evolve do **non linear transformation** with <code>nn.ReLU()</code> (Rectified Linear Unit), that rplace all the negatives with **zeros**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.io import *\n",
    "from fastai.metrics import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF \n",
    "\n",
    "**Pre-pocessing**:\n",
    "- <code>proc_df</code>\n",
    "    - split time and date to capture the trend\n",
    "    - replace nas with column's median (create nas dict)\n",
    "    - convert string to categories \n",
    "    - specify order of levels (low-mid-high)\n",
    "    - split independent and dependent vabiales\n",
    "    - one-hot-econded categorical variables (no more than 7-8 leveles)\n",
    "\n",
    "- <code>split_vals</code>\n",
    "    - split the dataset in training and validation set \n",
    "    - do not shuffle if time is involved\n",
    "\n",
    "**Compute the model**\n",
    "- <code>RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)</code>\n",
    "    - number of tree\n",
    "    - depth of the tree\n",
    "**Fit the model**\n",
    "- <code>m.fit(X_train, y_train)</code>\n",
    "    \n",
    "**Predict the dependent variable**\n",
    "- <code>m.predict(X_train), y_train)</code>\n",
    "\n",
    "**Check results**\n",
    "- <code>m.score(X_train, y_train)</code>\n",
    "    - proportion of the variance in the dependent variable that is predictable from the independent variable\n",
    "- <code>m.oob_score_</code>\n",
    "    - quantify overfitting\n",
    "    - calculate error on the training set, but only include the trees in the calculation of a row's error where that row was not included in training that tree.\n",
    "\n",
    "**Reduce overfitting**\n",
    "- Sub-sampling with `set_rf_samples(20000)`\n",
    "- Increase tree number (bagging) `n_estimators`\n",
    "- Descrease tree depth `min_samples_leaf`\n",
    "- Reduce the number of columns used `max_features`\n",
    "\n",
    "**Tree interpratatio and model improvement**\n",
    "- Confidence of prediction based on tree variance\n",
    "- Features importance `rf_feat_importance(m, df_trn)`\n",
    "- Remove redundant features with hierarchy tree\n",
    "- Partial dependece plot\n",
    "- Tree interpreter\n",
    "- Extrapolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN with SGD \n",
    "A neural network is an infinitely flexible function, consisting of layers. A layer is a linear function such as matrix multiplication followed by a non-linear function (the activation).  \n",
    "\n",
    "The final goal is to find the best paramenter for the a function to approximate aour dataset.  \n",
    "\n",
    "Most datasets will not be well-represented by a line. We could use a more complicated function, such as 𝑔(𝑥)=𝑎𝑥2+𝑏𝑥+𝑐+sin𝑑. Now we have 4 parameters to learn: 𝑎, 𝑏, 𝑐, and 𝑑. This function is more flexible than 𝑓(𝑥)=𝑎𝑥+𝑏 and will be able to accurately model more datasets.\n",
    "\n",
    "Neural networks take this to an extreme, and are infinitely flexible. They often have thousands, or even hundreds of thousands of parameters. However the core idea is the same as above. The neural network is a function, and we will learn the best parameters for modeling our data.\n",
    "\n",
    "#### Pre-processing\n",
    "- data normalization, `x=(x-mean)/std` to get mean=0 and sd=1\n",
    "- reshape from 1D to 2D and vice-versa with `np.reshape()`\n",
    "\n",
    "#### Define the net\n",
    "\n",
    "- One single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(28*28, 10),\n",
    "    nn.LogSoftmax()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multiple layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(28*28, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10),\n",
    "    nn.LogSoftmax()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.NLLLoss()\n",
    "metrics=[accuracy]\n",
    "opt=optim.SGD(net.parameters(), 1e-1, momentum=0.9, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning the **loss** function or cost function is representing the price paid for inaccuracy of predictions.\n",
    "\n",
    "The loss associated with one example in binary classification is given by:\n",
    "`-(y * log(p) + (1-y) * log (1-p))`\n",
    "where `y` is the true label of `x` and `p` is the probability predicted by our model that the label is 1.  \n",
    "\n",
    "For multi-class classification, we use negative log liklihood (also known as categorical cross entropy) which is exactly the same thing, but summed up over all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(net, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(net, md.val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
